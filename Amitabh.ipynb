{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "#NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_raw = pd.read_csv(\"D:\\Codes\\PROJECT 2\\hashtag_donaldtrump.csv\",\n",
    "                 lineterminator='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_raw = pd.read_csv(\"D:\\Codes\\PROJECT 2\\hashtag_joebiden.csv\",\n",
    "                 lineterminator='\\n')\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data has (rows x col)(675765, 13)\n",
      "total NaN values in this dataFrame: 0\n"
     ]
    }
   ],
   "source": [
    "#Removes columns of data with very high Na values. \n",
    "trump=trump_raw.drop(['user_description','long','lat','city','country','continent',\n",
    "'state','state_code'], axis=1)\n",
    "\n",
    "#remove rows of data with less NaN values\n",
    "trump=trump.dropna(subset=['user_name','source','user_location'])\n",
    "\n",
    "print(f\"This data has (rows x col){trump.shape}\")\n",
    "print(f\"total NaN values in this dataFrame: {trump.isna().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data has (rows x col)(542952, 13)\n",
      "total NaN values in this dataFrame: 0\n"
     ]
    }
   ],
   "source": [
    "#Removes columns of data with very high Na values. \n",
    "biden=biden_raw.drop(['user_description','long','lat','city','country','continent',\n",
    "'state','state_code'], axis=1)\n",
    "\n",
    "#remove rows of data with less NaN values\n",
    "biden=biden.dropna(subset=['user_name','source','user_location'])\n",
    "\n",
    "print(f\"This data has (rows x col){biden.shape}\")\n",
    "print(f\"total NaN values in this dataFrame: {biden.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Philadelphia, PA / Miami, FL\n",
       "2                        Portland\n",
       "4                   Washington DC\n",
       "5               Perris,California\n",
       "6                      Powell, TN\n",
       "Name: user_location, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump['user_location'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_join_date</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>collected_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-15 00:00:01</td>\n",
       "      <td>1.316529e+18</td>\n",
       "      <td>#Elecciones2020 | En #Florida: #JoeBiden dice ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>3.606665e+08</td>\n",
       "      <td>El Sol Latino News</td>\n",
       "      <td>elsollatinonews</td>\n",
       "      <td>2011-08-23 15:33:45</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>Philadelphia, PA / Miami, FL</td>\n",
       "      <td>2020-10-21 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-15 00:00:02</td>\n",
       "      <td>1.316529e+18</td>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>8.436472e+06</td>\n",
       "      <td>snarke</td>\n",
       "      <td>snarke</td>\n",
       "      <td>2007-08-26 05:56:11</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>Portland</td>\n",
       "      <td>2020-10-21 00:00:00.746433060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-15 00:00:08</td>\n",
       "      <td>1.316529e+18</td>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‘s ra...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>4.741380e+07</td>\n",
       "      <td>Rana Abtar - رنا أبتر</td>\n",
       "      <td>Ranaabtar</td>\n",
       "      <td>2009-06-15 19:05:35</td>\n",
       "      <td>5393.0</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>2020-10-21 00:00:01.492866121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-10-15 00:00:17</td>\n",
       "      <td>1.316529e+18</td>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1.138416e+09</td>\n",
       "      <td>Farris Flagg</td>\n",
       "      <td>FarrisFlagg</td>\n",
       "      <td>2013-02-01 01:37:38</td>\n",
       "      <td>2363.0</td>\n",
       "      <td>Perris,California</td>\n",
       "      <td>2020-10-21 00:00:01.866082651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-10-15 00:00:17</td>\n",
       "      <td>1.316529e+18</td>\n",
       "      <td>@richardmarx Glad u got out of the house! DICK...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>7.674018e+17</td>\n",
       "      <td>Michael Wilson</td>\n",
       "      <td>wilsonfire9</td>\n",
       "      <td>2016-08-21 16:43:51</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Powell, TN</td>\n",
       "      <td>2020-10-21 00:00:02.239299182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at      tweet_id  \\\n",
       "0  2020-10-15 00:00:01  1.316529e+18   \n",
       "2  2020-10-15 00:00:02  1.316529e+18   \n",
       "4  2020-10-15 00:00:08  1.316529e+18   \n",
       "5  2020-10-15 00:00:17  1.316529e+18   \n",
       "6  2020-10-15 00:00:17  1.316529e+18   \n",
       "\n",
       "                                               tweet  likes  retweet_count  \\\n",
       "0  #Elecciones2020 | En #Florida: #JoeBiden dice ...    0.0            0.0   \n",
       "2  #Trump: As a student I used to hear for years,...    2.0            1.0   \n",
       "4  You get a tie! And you get a tie! #Trump ‘s ra...    4.0            3.0   \n",
       "5  @CLady62 Her 15 minutes were over long time ag...    2.0            0.0   \n",
       "6  @richardmarx Glad u got out of the house! DICK...    0.0            0.0   \n",
       "\n",
       "                source       user_id              user_name user_screen_name  \\\n",
       "0            TweetDeck  3.606665e+08     El Sol Latino News  elsollatinonews   \n",
       "2      Twitter Web App  8.436472e+06                 snarke           snarke   \n",
       "4   Twitter for iPhone  4.741380e+07  Rana Abtar - رنا أبتر        Ranaabtar   \n",
       "5  Twitter for Android  1.138416e+09           Farris Flagg      FarrisFlagg   \n",
       "6   Twitter for iPhone  7.674018e+17         Michael Wilson      wilsonfire9   \n",
       "\n",
       "        user_join_date  user_followers_count                 user_location  \\\n",
       "0  2011-08-23 15:33:45                1860.0  Philadelphia, PA / Miami, FL   \n",
       "2  2007-08-26 05:56:11                1185.0                      Portland   \n",
       "4  2009-06-15 19:05:35                5393.0                 Washington DC   \n",
       "5  2013-02-01 01:37:38                2363.0             Perris,California   \n",
       "6  2016-08-21 16:43:51                  75.0                    Powell, TN   \n",
       "\n",
       "                    collected_at  \n",
       "0            2020-10-21 00:00:00  \n",
       "2  2020-10-21 00:00:00.746433060  \n",
       "4  2020-10-21 00:00:01.492866121  \n",
       "5  2020-10-21 00:00:01.866082651  \n",
       "6  2020-10-21 00:00:02.239299182  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x={}\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for tweet in trump['tweet']:\n",
    "    x[i]=process_tweet(tweet)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(x)\n",
    "\n",
    "\n",
    "type(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [eleccion, 2020, en, florida, joebiden, dice, ...\n",
       "1         [trump, student, use, hear, year, ten, year, h...\n",
       "2               [get, tie, get, tie, trump, ‘, ralli, iowa]\n",
       "3         [15, minut, long, time, ago, omarosa, never, r...\n",
       "4         [glad, u, got, hous, dick, trump, 2020, 💪, 🏽, ...\n",
       "                                ...                        \n",
       "675760    [13, email, trump, trumpett, today, 20, sat, d...\n",
       "675761    [unlik, mussolini, hitler, mao, lenin, stalin,...\n",
       "675762    [stop, lay, pari, london, dont, give, fuck, bi...\n",
       "675763    [afd, ler, reagieren, panisch, bi, hysterisch,...\n",
       "675764                           [ok, trump, catapulttrump]\n",
       "Length: 675765, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'D:\\\\Codes\\\\PROJECT 2\\\\processed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14052/1673155218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"D:\\Codes\\PROJECT 2\\processed.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;34m\"D:\\Codes\\PROJECT 2\\Shehroz.ipynb\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env1\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env1\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env1\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env1\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'D:\\\\Codes\\\\PROJECT 2\\\\processed.csv'"
     ]
    }
   ],
   "source": [
    "s.to_csv(r\"D:\\Codes\\PROJECT 2\\processed.csv\")\n",
    "\n",
    "\"D:\\Codes\\PROJECT 2\\Shehroz.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f54b37df60922bf9004f875190b152fc8aec9878039a93ede93ec8983c432aa5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
